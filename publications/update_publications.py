#!/usr/bin/env python3
"""
update_publications.py
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Ğ¡ĞºĞ°Ñ‡Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ· Ğ´Ğ²ÑƒÑ… Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ĞµĞ¹ Google Scholar
  â€¢ Ruslan Afasizhev  (U7yVbHIAAAAJ)
  â€¢ Inna Afasizheva   (-ivXdnsAAAAJ)

â–ª ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑĞµÑ‚ JSON Ğ²  publications/gs_json/â€¦
â–ª Ğ¿ĞµÑ€ĞµĞ·Ğ°Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°ĞµÑ‚ Ğ±Ğ»Ğ¾Ğº  <section id="publications"> â€¦ </section>  Ğ² index.html

pip install "scholarly>=1.7.11"
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""
from __future__ import annotations

import json, re, sys
from datetime import datetime
from pathlib   import Path
from typing    import Dict, List, Tuple

from scholarly import scholarly


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Ğ¿ÑƒÑ‚Ğ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SCRIPT_DIR = Path(__file__).resolve().parent         # â€¦/publications
REPO_DIR   = SCRIPT_DIR.parent                       # â€¦/afasilab.github.io
INDEX_HTML = REPO_DIR / "index.html"

GS_DIR   = REPO_DIR / "publications" / "gs_json"
GS_DIR.mkdir(parents=True, exist_ok=True)

today     = datetime.today().strftime("%m-%d-%Y")
JSON_FILE = GS_DIR / f"publications_detailed_{today}.json"
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


AUTHOR_IDS: Dict[str, str] = {
    "Ruslan Afasizhev": "U7yVbHIAAAAJ",
    "Inna Afasizheva":  "-ivXdnsAAAAJ",
}


# â•â•â•â•â•â•â•â•â•â•â•â•â• helpers â•â•â•â•â•â•â•â•â•â•â•â•â•
def fetch_author_pubs(author_id: str) -> List[dict]:
    """Ğ¡Ğ¾Ğ±Ñ€Ğ°Ñ‚ÑŒ ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¹ Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ° Ğ¿Ğ¾ ĞµĞ³Ğ¾ ID."""
    base = scholarly.search_author_id(author_id)
    full = scholarly.fill(base, sections=["publications"])
    pubs: List[dict] = []
    for p in full["publications"]:
        filled = scholarly.fill(p)
        bib    = filled.get("bib", {})
        pubs.append(
            {
                "title":        bib.get("title", ""),
                "authors":      bib.get("author", ""),
                "year":         bib.get("pub_year", ""),
                "journal":      bib.get("journal", ""),
                "volume":       bib.get("volume", ""),
                "number":       bib.get("number", ""),
                "pages":        bib.get("pages", ""),
                "publisher":    bib.get("publisher", ""),
                "citation":     bib.get("citation", ""),
                "num_citations": filled.get("num_citations", 0),
                "pub_url":      filled.get("pub_url", ""),
            }
        )
    return pubs


def best_link(pub: dict) -> str:
    """ĞÑ‚Ğ´Ğ°Ñ‚ÑŒ DOI â†’ PMID â†’ fallbackâ€URL."""
    blob = f'{pub.get("citation","")} {pub.get("pub_url","")}'
    doi  = re.search(r"(10\.\d{4,9}/[-._;()/:A-Za-z0-9]+)", blob)
    if doi:
        return f"https://doi.org/{doi.group(1)}"
    pmid = re.search(r"pubmed\.ncbi\.nlm\.nih\.gov/(\d{4,9})", blob)
    if pmid:
        return f"https://pubmed.ncbi.nlm.nih.gov/{pmid.group(1)}/"
    return pub.get("pub_url", "")


def short_authors(auths: str, keep: int = 3) -> str:
    """Ğ¡Ğ¾ĞºÑ€Ğ°Ñ‚Ğ¸Ñ‚ÑŒ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğ¹ ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ¾Ğ² Ğ´Ğ¾ Â«A, B, C et al.Â»."""
    names = [a.strip() for a in auths.split(" and ")]
    return (", ".join(names[:keep]) + " et al.") if len(names) > keep + 3 else ", ".join(names)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. ÑĞ¾Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
all_pubs: List[dict] = []
for name, aid in AUTHOR_IDS.items():
    print(f"ğŸ“¥  Fetching {name} â€¦")
    try:
        all_pubs += fetch_author_pubs(aid)
    except Exception as e:                         # noqa: BLE001
        print(f"âš ï¸  {name}: {e}", file=sys.stderr)

uniq: Dict[Tuple[str, str], dict] = {}
for p in all_pubs:                                # Ğ´ĞµĞ´ÑƒĞ¿Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ñ
    key = (p["title"].lower().strip(), p.get("year"))
    uniq.setdefault(key, p)

publications = [p for p in uniq.values() if p.get("year")]
publications.sort(key=lambda x: int(x["year"]), reverse=True)

print(f"ğŸ”¢  Unique publications: {len(publications)}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ JSON â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
JSON_FILE.write_text(json.dumps(publications, ensure_ascii=False, indent=2), encoding="utf-8")
print(f"ğŸ’¾  Saved â†’ {JSON_FILE.relative_to(REPO_DIR)}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼ HTML â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
block_lines: List[str] = []
for p in publications:
    link = best_link(p)
    cite = (
        f'{short_authors(p["authors"])}. '
        f'<a href="{link}" target="_blank" class="ext">{p["title"]}</a>.'
    )
    if p["journal"]:
        cite += f' <em>{p["journal"]}</em>'
    if p["volume"]:
        cite += f', <strong>{p["volume"]}</strong>'
    if p["number"]:
        cite += f'({p["number"]})'
    if p["pages"]:
        cite += f', {p["pages"]}'
    cite += f', {p["year"]}.'
    block_lines.append(f'    <div class="pub-entry"><p>{cite}</p></div>')

new_section = (
    "<section id=\"publications\">\n"
    "  <h2>Publications</h2>\n"
    "  <div class=\"publications\">\n"
    + "\n".join(block_lines) + "\n"
    "  </div>\n"
    "</section>"
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4. Ğ²ÑÑ‚Ñ€Ğ°Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ² index.html â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
html_src = INDEX_HTML.read_text(encoding="utf-8")
updated  = re.sub(
    r'<section[^>]*id=["\']publications["\'][\s\S]*?</section>',
    new_section,
    html_src,
    flags=re.IGNORECASE | re.DOTALL,
)

if updated != html_src:
    INDEX_HTML.write_text(updated, encoding="utf-8")
    print("âœ…  index.html updated")
else:
    print("â„¹ï¸  index.html ÑƒĞ¶Ğµ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ ÑĞ²ĞµĞ¶Ğ¸Ğ¹ Ğ±Ğ»Ğ¾Ğº â€“ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹ Ğ½ĞµÑ‚")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5. CSS-Ğ¿Ğ¾Ğ´ÑĞºĞ°Ğ·ĞºĞ° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
hint_css = """
/* publications */
.pub-entry       { margin:0 0 .9rem 0; line-height:1.45; }
.pub-entry p     { text-indent:-1.6em; padding-left:1.6em; }
.pub-entry a.ext::after{
  content:"â†—"; font-size:.75em; margin-left:.15em;
  vertical-align:super; opacity:.6;
}
""".strip()

style_path = REPO_DIR / "css" / "styles.css"
if "pub-entry a.ext::after" not in style_path.read_text(encoding="utf-8"):
    print(
        f"""\nâ„¹ï¸  Ğ”Ğ¾Ğ±Ğ°Ğ²ÑŒÑ‚Ğµ Ğ² css/styles.css Ğ´Ğ»Ñ Ğ°ĞºĞºÑƒÑ€Ğ°Ñ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ²Ğ¸Ğ´Ğ° ÑÑÑ‹Ğ»Ğ¾Ğº:
{hint_css}
"""
    )
