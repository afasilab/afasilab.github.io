#!/usr/bin/env python3
"""
update_publications.py
-------------------------------------------
–°–æ–±–∏—Ä–∞–µ—Ç –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ —Å—Ä–∞–∑—É —É –¥–≤—É—Ö –ø—Ä–æ—Ñ–∏–ª–µ–π (Google Scholar) ‚Äî
Ruslan Afasizhev –∏ Inna Afasizheva,
–∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç JSON –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç
—Å–µ–∫—Ü–∏—é <section id="publications"> ‚Ä¶ </section> –≤ index.html
-------------------------------------------
pip install scholarly==1.7.11   # –≤–µ—Ä—Å–∏—è ‚â•1.7 (–ª—É—á—à–µ –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞—Ç—å)
"""

import json, re
from datetime import datetime
from pathlib import Path

from scholarly import scholarly

# ---------- –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ ----------
AUTHOR_IDS = {
    "Ruslan Afasizhev": "U7yVbHIAAAAJ",
    "Inna Afasizheva": "ivXdnsAAAAJ&hl",  # https://scholar.google.com/citations?user=-ivXdnsAAAAJ&hl=en
}

BASE_DIR  = Path(__file__).resolve().parent        # ‚Ä¶/afasilab.github.io
GS_DIR    = BASE_DIR / "publications" / "gs_json"
INDEX_HTML = BASE_DIR / "index.html"

GS_DIR.mkdir(parents=True, exist_ok=True)
today     = datetime.today().strftime("%m-%d-%Y")
json_file = GS_DIR / f"publications_detailed_{today}.json"
# ---------------------------------

def fetch_author_pubs(aid: str) -> list[dict]:
    """–í–µ—Ä–Ω—É—Ç—å —Å–ø–∏—Å–æ–∫ –ø—É–±–ª–∏–∫–∞—Ü–∏–π –∞–≤—Ç–æ—Ä–∞ –ø–æ Google-Scholar ID."""
    author_base = scholarly.search_author_id(aid)
    author_full = scholarly.fill(author_base, sections=["publications"])
    pubs = []
    for pub in author_full["publications"]:
        filled = scholarly.fill(pub)
        bib    = filled.get("bib", {})
        pubs.append(
            {
                "title":       bib.get("title", ""),
                "authors":     bib.get("author", ""),
                "year":        bib.get("pub_year", ""),
                "journal":     bib.get("journal", ""),
                "volume":      bib.get("volume", ""),
                "number":      bib.get("number", ""),
                "pages":       bib.get("pages", ""),
                "publisher":   bib.get("publisher", ""),
                "abstract":    bib.get("abstract", ""),
                "num_citations": filled.get("num_citations", 0),
                "pub_url":     filled.get("pub_url", ""),
            }
        )
    return pubs


# ---------- 1. —Å–æ–±–∏—Ä–∞–µ–º –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ–º ----------
all_pubs = []
for name, aid in AUTHOR_IDS.items():
    print(f"üì•  Fetching publications for {name} ‚Ä¶")
    all_pubs.extend(fetch_author_pubs(aid))

# –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è (–ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é + –≥–æ–¥—É)
unique = {}
for p in all_pubs:
    key = (p["title"].lower().strip(), p.get("year"))
    if key not in unique:
        unique[key] = p
publications = list(unique.values())

# —Ñ–∏–ª—å—Ç—Ä –ø–æ –≥–æ–¥—É + —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞
publications = [p for p in publications if p.get("year")]
publications.sort(key=lambda x: int(x["year"]), reverse=True)

# ---------- 2. —Å–æ—Ö—Ä–∞–Ω—è–µ–º JSON ----------
with json_file.open("w", encoding="utf-8") as f:
    json.dump(publications, f, ensure_ascii=False, indent=2)
print(f"üíæ  Saved metadata ‚Üí {json_file.relative_to(BASE_DIR)}")

# ---------- 3. –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º HTML ----------
blocks = []
for p in publications:
    authors = p["authors"]
    title   = p["title"]
    journal = p["journal"]; volume = p["volume"]
    number  = p["number"];  pages  = p["pages"]
    year    = p["year"];    url    = p["pub_url"]

    cite = f"{authors}. {title}."
    if journal: cite += f" <em>{journal}</em>"
    if volume:  cite += f", <strong>{volume}</strong>"
    if number:  cite += f"({number})"
    if pages:   cite += f", {pages}"
    cite += f", {year}."

    blocks.append(
        f"""    <div class="pub-entry">
      <p>{cite}<br><em>(<a href="{url}" target="_blank">Link</a>)</em></p>
    </div>"""
    )

pub_section = f"""
<section id="publications">
  <h2>Publications</h2>
  <div class="publications">
{chr(10).join(blocks)}
  </div>
</section>
"""

# ---------- 4. –≤—Å—Ç–∞–≤–ª—è–µ–º –≤ index.html ----------
html_text = INDEX_HTML.read_text(encoding="utf-8")
html_text = re.sub(
    r"<section id=\"publications\">[\\s\\S]*?</section>",
    pub_section,
    html_text,
    flags=re.DOTALL,
)
INDEX_HTML.write_text(html_text, encoding="utf-8")
print("‚úÖ index.html updated with fresh publication list")
